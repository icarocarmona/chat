{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessar spark-shell ustilizando o comanda abaixo\n",
    "\n",
    "./bin/spark-shell --packages com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.7,org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neste passo iremos criar um Data Frame onde será armazenado as mensagens do Kafka\n",
    "val kafkaDF = spark.readStream.format(\"kafka\").\n",
    "option(\"kafka.bootstrap.servers\", \"localhost:9092\").\n",
    "option(\"subscribe\",\"kafka-chat\").\n",
    "load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertendo as mensagens do kafka para String\n",
    "val chatString = kafkaDF.selectExpr(\"CAST(value AS STRING)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "\n",
    "val schema = new StructType().\n",
    "                    add(\"author\",StringType).\n",
    "                    add(\"message\",StringType)\n",
    "\n",
    "        \n",
    "val messages = chatString.\n",
    "                    select(from_json(col(\"value\"), schema).\n",
    "                    as(\"data\")).\n",
    "                    select(\"data.*\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe os dados no console\n",
    "val query = messages.writeStream.\n",
    "                outputMode(\"append\").\n",
    "                format(\"console\").\n",
    "                start();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações necessárias para  acessar um bucket no AWS\n",
    "\n",
    "spark.sparkContext.hadoopConfiguration.set(\"fs.s3a.access.key\", \"key\")\n",
    "spark.sparkContext.hadoopConfiguration.set(\"fs.s3a.secret.key\", \"secret\")\n",
    "spark.sparkContext.hadoopConfiguration.set(\"fs.s3a.impl\",\"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "spark.sparkContext.hadoopConfiguration.set(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "spark.sparkContext.hadoopConfiguration.set(\"fs.s3a.aws.credentials.provider\",\"org.apache.hadoop.fs.s3a.BasicAWSCredentialsProvider\")\n",
    "spark.sparkContext.hadoopConfiguration.set(\"fs.s3a.endpoint\", \"s3.amazonaws.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.DataFrame;\n",
    "\n",
    "val query1 = messages.\n",
    "    writeStream.\n",
    "    foreachBatch { (batchDF: DataFrame, batchId: Long) =>   \n",
    "                    batchDF.write.mode(\"append\").csv(\"s3a://buckt/csv/chat\") \n",
    "                 }.start();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}